{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The grand quest: make it actually work (4 points)\n",
    "\n",
    "Your main task is to use some of the tricks you've learned on the network and analyze if you can improve __validation MAE__. Try __at least 3 options__ from the list below for a passing grade. Write a short report about what you have tried. More ideas = more bonus points. \n",
    "\n",
    "__Please be serious:__ \" plot learning curves in MAE/epoch, compare models based on optimal performance, test one change at a time. You know the drill :)\n",
    "\n",
    "You can use either pure __tensorflow__ or __keras__. Feel free to adapt the seminar code for your needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/Train_rev1.csv\", index_col=None).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubbish_columns = ['Id', 'LocationRaw', 'SalaryRaw', 'SourceName', 'SalaryNormalized']\n",
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "import sklearn.preprocessing\n",
    "import nltk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_general(data):\n",
    "    new_data = pd.DataFrame(index=data.index)\n",
    "    for column in text_columns + categorical_columns:\n",
    "        new_data[column] = data[column]\n",
    "    new_data = new_data.fillna('NaN')\n",
    "    return new_data, np.log1p(data['SalaryNormalized']).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessCategorical(TransformerMixin):\n",
    "    def __init__(self, min_company=40, min_city=20):\n",
    "        self.le_category = sklearn.preprocessing.LabelEncoder()\n",
    "        self.le_type = sklearn.preprocessing.LabelEncoder()\n",
    "        self.city_counter = Counter()\n",
    "        self.company_counter = Counter()\n",
    "        self.min_company = min_company\n",
    "        self.min_city = min_city\n",
    "        self.mean = {}\n",
    "        \n",
    "    def _fit_category(self, data):\n",
    "        self.le_category.fit(np.concatenate([data['Category'], ['other']]))\n",
    "        \n",
    "    def _fit_type(self, data):\n",
    "        self.le_type.fit(data['ContractTime'] + data['ContractType'])\n",
    "        \n",
    "    def _fit_city_company(self, data, what, minimum, target):\n",
    "        keys = {value if count >= minimum else 'other' for value, count in Counter(data[what]).most_common()}\n",
    "        tmp_data = pd.DataFrame(index=data.index)\n",
    "        tmp_data[what] = data[what].apply(lambda value: value if value in keys else 'other')\n",
    "        tmp_data['Salary'] = target\n",
    "        self.mean[what] = tmp_data.groupby(what)['Salary'].mean()\n",
    "        \n",
    "    def fit(self, data, target):\n",
    "        self._fit_category(data)\n",
    "        self._fit_city_company(data, 'LocationNormalized', self.min_city, target)\n",
    "        self._fit_city_company(data, 'Company', self.min_company, target)\n",
    "        self._fit_type(data)\n",
    "        return self\n",
    "    \n",
    "    def _transform_category(self, data, new_data):\n",
    "        new_data['Category'] = self.le_category.transform(data['Category'])\n",
    "    \n",
    "    def _transform_type(self, data, new_data):\n",
    "        new_data['Contract'] = self.le_type.transform(data['ContractTime'] + data['ContractType'])\n",
    "        \n",
    "        \n",
    "    def _transform_city_company(self, data, what, new_data):\n",
    "        new_data[what] = data[what].apply(lambda value: self.mean[what].get(value, self.mean[what]['other']))\n",
    "        \n",
    "    def transform(self, data):\n",
    "        new_data = pd.DataFrame(index=data.index)\n",
    "        self._transform_category(data, new_data)\n",
    "        self._transform_type(data, new_data)\n",
    "        self._transform_city_company(data, 'LocationNormalized', new_data)\n",
    "        self._transform_city_company(data, 'Company', new_data)\n",
    "        for column in data:\n",
    "            if column not in categorical_columns:\n",
    "                new_data[column] = data[column]\n",
    "        return new_data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessText(TransformerMixin):\n",
    "    def __init__(self, min_count = 10):\n",
    "        self.tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "        self.min_count = min_count\n",
    "        \n",
    "    def fit(self, data, target=None):\n",
    "        token_counts = Counter(' '.join(data['Title']).split())\n",
    "        token_counts += Counter(' '.join(data['FullDescription']).split())\n",
    "        self.tokens = [\"PAD\", \"UNK\"] + [token for token, count in token_counts.items() if count >= self.min_count]\n",
    "        self.token_to_id = {token: index for index, token in enumerate(self.tokens)}\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        new_data = pd.DataFrame(index=data.index)\n",
    "        for column in data:\n",
    "            new_data[column] = data[column].apply(\n",
    "                lambda text: list(map(lambda word: self.token_to_id.get(word, 0), \n",
    "                                      self.tokenizer.tokenize(str(text).lower()))\n",
    "                                 )\n",
    "            ) if column in text_columns else data[column]\n",
    "        return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, target = preprocess_general(data)\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.3, random_state=325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PreprocessCategorical at 0x7feea23c3c18>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_text = PreprocessText()\n",
    "prep_cat = PreprocessCategorical()\n",
    "prep_text.fit(data_train)\n",
    "prep_cat.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = prep_text.transform(prep_cat.transform(data_train))\n",
    "data_test = prep_text.transform(prep_cat.transform(data_test))\n",
    "vocab = prep_text.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv('data/data_prep_train.csv')\n",
    "data_test.to_csv('data/data_prep_test.csv')\n",
    "target_train.to_csv('data/target_train.csv')\n",
    "target_test.to_csv('data/target_test.csv')\n",
    "pd.DataFrame(vocab).to_csv('data/vocab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data_train = pd.read_csv('data/data_prep_train.csv', index_col=0)\n",
    "data_test = pd.read_csv('data/data_prep_test.csv', index_col=0)\n",
    "for data in data_train, data_test:\n",
    "    for column in text_columns:\n",
    "        data[column] = data[column].apply(json.loads)\n",
    "target_train = pd.read_csv('data/target_train.csv', index_col=0)\n",
    "target_test = pd.read_csv('data/target_test.csv', index_col=0)\n",
    "vocab = pd.read_csv('data/vocab.csv', index_col=0).values[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 28275, 146657,  73853, 158965, 188818,  63645, 223710, 148653,\n",
       "             49666,  88847,\n",
       "            ...\n",
       "            241556, 135564,   3920,  37822, 214359,  97894, 114385,  98588,\n",
       "            170890, 165969],\n",
       "           dtype='int64', length=171337)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [145870, 60044, 84190, 145699, 19529, 78946, 6452, 97752, 119591, 123033, 58918, 19663, 114791, 15335, 39073, 1725, 52149, 59793, 115934, 110450, 141889, 139812, 50591, 77724, 74148, 72997, 86634, 50457, 136237, 167056, 111, 78692, 132171, 34982, 21299, 3690, 26901, 60926, 35092, 134985, 115368, 144064, 99252, 129396, 128598, 22202, 142663, 131428, 66701, 44634, 37555, 6947, 62270, 107257, 158569, 36195, 87638, 125, 8300, 69535, 81779, 37398, 57211, 31072, 26863, 126242, 60237, 43676, 97142, 122028, 30173, 120316, 13048, 155096, 88460, 121406, 157502, 12709, 161977, 1584, 30009, 143710, 110077, 69880, 142797, 81611, 125105, 17696, 62001, 87536, 40470, 137905, 136452, 143030, 95182, 164850, 31441, 72614, 41581, 113562]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10.532123</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28275</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177397</th>\n",
       "      <td>10.463132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75929</th>\n",
       "      <td>9.564583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4766</th>\n",
       "      <td>10.021315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204734</th>\n",
       "      <td>10.463132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12920</th>\n",
       "      <td>10.915107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52646</th>\n",
       "      <td>10.221977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140153</th>\n",
       "      <td>10.308986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120476</th>\n",
       "      <td>9.113939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127723</th>\n",
       "      <td>9.952325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>10.571342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74005</th>\n",
       "      <td>10.463132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233580</th>\n",
       "      <td>9.903538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143011</th>\n",
       "      <td>10.768506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225859</th>\n",
       "      <td>11.225257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131041</th>\n",
       "      <td>10.199175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66715</th>\n",
       "      <td>10.085851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219823</th>\n",
       "      <td>10.239996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118049</th>\n",
       "      <td>11.425743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49619</th>\n",
       "      <td>11.248973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178544</th>\n",
       "      <td>10.819798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160064</th>\n",
       "      <td>9.862718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137444</th>\n",
       "      <td>10.474495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22310</th>\n",
       "      <td>9.843632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13866</th>\n",
       "      <td>10.126671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194594</th>\n",
       "      <td>10.126671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202271</th>\n",
       "      <td>10.491302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244070</th>\n",
       "      <td>10.341775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106117</th>\n",
       "      <td>10.064798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152201</th>\n",
       "      <td>10.165891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19738</th>\n",
       "      <td>10.768506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185251</th>\n",
       "      <td>10.668979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8501</th>\n",
       "      <td>9.798182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117384</th>\n",
       "      <td>10.818197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155394</th>\n",
       "      <td>10.703267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69590</th>\n",
       "      <td>9.784197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199321</th>\n",
       "      <td>9.700208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101303</th>\n",
       "      <td>10.373523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45050</th>\n",
       "      <td>10.645449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190225</th>\n",
       "      <td>10.221977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187249</th>\n",
       "      <td>9.575053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70212</th>\n",
       "      <td>10.239996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229378</th>\n",
       "      <td>9.741028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226569</th>\n",
       "      <td>10.221977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229589</th>\n",
       "      <td>10.389026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48938</th>\n",
       "      <td>9.615872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40573</th>\n",
       "      <td>10.389026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191271</th>\n",
       "      <td>10.268166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62146</th>\n",
       "      <td>10.571342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33898</th>\n",
       "      <td>10.673619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56979</th>\n",
       "      <td>10.221977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52187</th>\n",
       "      <td>9.869569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127621</th>\n",
       "      <td>10.106469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28350</th>\n",
       "      <td>10.308986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20857</th>\n",
       "      <td>10.203629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224519</th>\n",
       "      <td>11.042922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224634</th>\n",
       "      <td>11.225257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38778</th>\n",
       "      <td>9.517090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168527</th>\n",
       "      <td>9.862718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57831</th>\n",
       "      <td>9.741028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221472</th>\n",
       "      <td>10.854083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        10.532123\n",
       "28275            \n",
       "177397  10.463132\n",
       "75929    9.564583\n",
       "4766    10.021315\n",
       "204734  10.463132\n",
       "12920   10.915107\n",
       "52646   10.221977\n",
       "140153  10.308986\n",
       "120476   9.113939\n",
       "127723   9.952325\n",
       "3697    10.571342\n",
       "74005   10.463132\n",
       "233580   9.903538\n",
       "143011  10.768506\n",
       "225859  11.225257\n",
       "131041  10.199175\n",
       "66715   10.085851\n",
       "219823  10.239996\n",
       "118049  11.425743\n",
       "49619   11.248973\n",
       "178544  10.819798\n",
       "160064   9.862718\n",
       "137444  10.474495\n",
       "22310    9.843632\n",
       "13866   10.126671\n",
       "194594  10.126671\n",
       "202271  10.491302\n",
       "244070  10.341775\n",
       "106117  10.064798\n",
       "152201  10.165891\n",
       "19738   10.768506\n",
       "...           ...\n",
       "185251  10.668979\n",
       "8501     9.798182\n",
       "117384  10.818197\n",
       "155394  10.703267\n",
       "69590    9.784197\n",
       "199321   9.700208\n",
       "101303  10.373523\n",
       "45050   10.645449\n",
       "190225  10.221977\n",
       "187249   9.575053\n",
       "70212   10.239996\n",
       "229378   9.741028\n",
       "226569  10.221977\n",
       "229589  10.389026\n",
       "48938    9.615872\n",
       "40573   10.389026\n",
       "191271  10.268166\n",
       "62146   10.571342\n",
       "33898   10.673619\n",
       "56979   10.221977\n",
       "52187    9.869569\n",
       "127621  10.106469\n",
       "28350   10.308986\n",
       "20857   10.203629\n",
       "224519  11.042922\n",
       "224634  11.225257\n",
       "38778    9.517090\n",
       "168527   9.862718\n",
       "57831    9.741028\n",
       "221472  10.854083\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.iloc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[145870  60044  84190 145699  19529  78946   6452  97752 119591 123033\\n  58918  19663 114791  15335  39073   1725  52149  59793 115934 110450\\n 141889 139812  50591  77724  74148  72997  86634  50457 136237 167056\\n    111  78692 132171  34982  21299   3690  26901  60926  35092 134985\\n 115368 144064  99252 129396 128598  22202 142663 131428  66701  44634\\n  37555   6947  62270 107257 158569  36195  87638    125   8300  69535\\n  81779  37398  57211  31072  26863 126242  60237  43676  97142 122028\\n  30173 120316  13048 155096  88460 121406 157502  12709 161977   1584\\n  30009 143710 110077  69880 142797  81611 125105  17696  62001  87536\\n  40470 137905 136452 143030  95182 164850  31441  72614  41581 113562] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d082a1d0035a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtarget_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2175\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1269\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[145870  60044  84190 145699  19529  78946   6452  97752 119591 123033\\n  58918  19663 114791  15335  39073   1725  52149  59793 115934 110450\\n 141889 139812  50591  77724  74148  72997  86634  50457 136237 167056\\n    111  78692 132171  34982  21299   3690  26901  60926  35092 134985\\n 115368 144064  99252 129396 128598  22202 142663 131428  66701  44634\\n  37555   6947  62270 107257 158569  36195  87638    125   8300  69535\\n  81779  37398  57211  31072  26863 126242  60237  43676  97142 122028\\n  30173 120316  13048 155096  88460 121406 157502  12709 161977   1584\\n  30009 143710 110077  69880 142797  81611 125105  17696  62001  87536\\n  40470 137905 136452 143030  95182 164850  31441  72614  41581 113562] not in index'"
     ]
    }
   ],
   "source": [
    "target_train[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batches iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input(data):\n",
    "    result = {}\n",
    "    for column in [\"Title\", \"FullDescription\"]:\n",
    "        max_len = max(map(len, data[column]))\n",
    "        result[column] = np.zeros([data.shape[0], max_len])\n",
    "        for index, line in enumerate(data[column]):\n",
    "            result[column][index][:len(line)] = np.array(line)\n",
    "            \n",
    "    for col in [\"Category\", \"Contract\", \"LocationNormalized\", \"Company\"]:\n",
    "        result[col] = np.array(data[col].values).reshape(data.shape[0])\n",
    "    return result\n",
    "\n",
    "def iter_batches(data, target=None, batch_size=100, shuffle=True, cycle=False):\n",
    "    \n",
    "    while True:\n",
    "        indices = np.arange(data.shape[0])\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(data), batch_size):\n",
    "            index = indices[start:start+batch_size]\n",
    "            if target is not None:\n",
    "                yield make_input(data.iloc[index]), target.iloc[index]\n",
    "            else:\n",
    "                yield make_input(data.iloc[index])\n",
    "                \n",
    "        if not cycle: break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_categorical_model(hid_size=32, category_size=15, contract_size=6):\n",
    "    category = L.Input(shape=(1,), name=\"Category\")\n",
    "    contract = L.Input(shape=(1,), name=\"Contract\")\n",
    "    location = L.Input(shape=(1,), name=\"LocationNormalized\")\n",
    "    company = L.Input(shape=(1,), name=\"Company\")\n",
    "    emb_category = L.Reshape((category_size,))(L.Embedding(29, category_size)(category))\n",
    "    emb_contract = L.Reshape((contract_size,))(L.Embedding(9, contract_size)(contract))\n",
    "    hidden_0 = L.Concatenate()([emb_category, emb_contract, location, company])\n",
    "    hidden_1 = L.Dense(units=hid_size, activation='relu')(hidden_0)\n",
    "    hidden_2 = L.Dense(units=hid_size, activation='relu')(hidden_1)\n",
    "    output = L.Dense(units=1)(hidden_2)\n",
    "    model = keras.models.Model(inputs=[category, contract, location, company], outputs=output)\n",
    "    return model\n",
    "\n",
    "def create_textual_model(emb_size=128):\n",
    "    vocab_size=len(vocab)\n",
    "    \n",
    "    title = L.Input(shape=(None,), name='Title')\n",
    "    descr = L.Input(shape=(None,), name='FullDescription')\n",
    "    emb_title = L.Embedding(vocab_size, emb_size)(title)\n",
    "    emb_descr = L.Embedding(vocab_size, emb_size)(descr)\n",
    "    conv_title = L.Conv1D(kernel_size=(2,), filters=32, activation='relu')(emb_title)\n",
    "    conv_descr = L.Conv1D(kernel_size=(4,), filters=64, activation='relu')(emb_descr)\n",
    "    pool_title = L.GlobalMaxPool1D()(conv_title)\n",
    "    pool_descr = L.GlobalMaxPool1D()(conv_descr)\n",
    "    recur_title_forward = L.LSTM(units=16, activation='relu')(emb_title)\n",
    "    recur_descr_forward = L.LSTM(units=32, activation='relu')(emb_descr)\n",
    "    recur_title_backward = L.LSTM(units=16, go_backwards=True, activation='relu')(emb_title)\n",
    "    recur_descr_backward = L.LSTM(units=32, go_backwards=True, activation='relu')(emb_descr)\n",
    "    hidden_0 = L.Concatenate()([\n",
    "        pool_title, pool_descr, \n",
    "        recur_title_forward, recur_descr_forward, \n",
    "        recur_title_backward, recur_descr_backward\n",
    "    ])\n",
    "    hidden_1 = L.Dense(emb_size, activation='relu')(hidden_0)\n",
    "    output = L.Dense(1)(hidden_1)\n",
    "    model = keras.models.Model(inputs=[title, descr], outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_testing_model(emb_size=10):\n",
    "    vocab_size=len(vocab)\n",
    "    title = L.Input(shape=(None,), name='Title')\n",
    "    emb_title = L.Embedding(vocab_size, emb_size)(title)\n",
    "    conv_title = L.Conv1D(kernel_size=(2, ), filters=64, activation='relu')(emb_title)\n",
    "    pool_title = L.GlobalMaxPool1D()(conv_title)\n",
    "    output = L.Dense(1)(pool_title)\n",
    "    model = keras.models.Model(inputs=title, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Title (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FullDescription (InputLayer)    (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 10)     630430      Title[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 10)     630430      FullDescription[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 32)     672         embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 64)     2624        embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 32)           0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 64)           0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 16)           1728        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 32)           5504        embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 16)           1728        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 32)           5504        embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 192)          0           global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           1930        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            11          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,280,561\n",
      "Trainable params: 1,280,561\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_textual_model(emb_size=10)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 31/100 [========>.....................] - ETA: 58s - loss: 96.5962"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-b107a02d0ee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2229\u001b[0m                         \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2231\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2233\u001b[0m                     \u001b[0mbatch_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# will be handled by on_epoch_end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mprev_total_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamic_display\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\b'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "steps_per_epoch = 100\n",
    "model.fit_generator(\n",
    "    iter_batches(data_train, target_train),\n",
    "    validation_data=iter_batches(data_test, target_test),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=10,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Series' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-377-bb7de4049c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_prep_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-375-ff16caac584b>\u001b[0m in \u001b[0;36miterate_minibatches\u001b[0;34m(data, batch_size, shuffle, cycle, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Series' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "next(iterate_minibatches(data_prep_train, target_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A short report\n",
    "\n",
    "Please tell us what you did and how did it work.\n",
    "\n",
    "`<YOUR_TEXT_HERE>`, i guess..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "233077",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-397-add422ddb01d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model.fit(make_input(data_prep_train), \n\u001b[0m\u001b[1;32m      4\u001b[0m           \u001b[0mtarget_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_prep_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-396-65e70aac1bcd>\u001b[0m in \u001b[0;36mmake_input\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Category\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Contract\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LocationNormalized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Company\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 233077"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.fit(make_input(data_prep_train), \n",
    "          target_train, \n",
    "          validation_data=(make_input(data_prep_test), target_test), \n",
    "          epochs=3\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.920802 9.784760475158691\n",
      "\n",
      "10.574045 10.96959400177002\n",
      "\n",
      "10.624446 10.915106773376465\n",
      "\n",
      "10.527648 10.389025688171387\n",
      "\n",
      "10.514307 9.615805625915527\n",
      "\n",
      "10.631734 10.95955753326416\n",
      "\n",
      "10.673228 10.505094528198242\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-31e8d877d403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_prep_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_prep_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, target in zip(data_prep_train.index, target_train):\n",
    "    print(model.predict(make_input(data_prep_train.loc[[i]]))[0][0], target)\n",
    "    input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended options\n",
    "\n",
    "#### A) CNN architecture\n",
    "\n",
    "All the tricks you know about dense and convolutional neural networks apply here as well.\n",
    "* Dropout. Nuff said.\n",
    "* Batch Norm. This time it's `L.BatchNormalization`\n",
    "* Parallel convolution layers. The idea is that you apply several nn.Conv1d to the same embeddings and concatenate output channels.\n",
    "* More layers, more neurons, ya know...\n",
    "\n",
    "\n",
    "#### B) Play with pooling\n",
    "\n",
    "There's more than one way to perform pooling:\n",
    "* Max over time - our `L.GlobalMaxPool1D`\n",
    "* Average over time (excluding PAD)\n",
    "* Softmax-pooling:\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot {{e ^ {h_{i, t}}} \\over \\sum_\\tau e ^ {h_{j, \\tau}} } }$$\n",
    "\n",
    "* Attentive pooling\n",
    "$$ out_{i, t} = \\sum_t {h_{i,t} \\cdot Attn(h_t)}$$\n",
    "\n",
    ", where $$ Attn(h_t) = {{e ^ {NN_{attn}(h_t)}} \\over \\sum_\\tau e ^ {NN_{attn}(h_\\tau)}}  $$\n",
    "and $NN_{attn}$ is a dense layer.\n",
    "\n",
    "The optimal score is usually achieved by concatenating several different poolings, including several attentive pooling with different $NN_{attn}$ (aka multi-headed attention).\n",
    "\n",
    "The catch is that keras layers do not inlude those toys. You will have to [write your own keras layer](https://keras.io/layers/writing-your-own-keras-layers/). Or use pure tensorflow, it might even be easier :)\n",
    "\n",
    "#### C) Fun with words\n",
    "\n",
    "It's not always a good idea to train embeddings from scratch. Here's a few tricks:\n",
    "\n",
    "* Use a pre-trained embeddings from `gensim.downloader.load`. See last lecture.\n",
    "* Start with pre-trained embeddings, then fine-tune them with gradient descent. You may or may not want to use __`.get_keras_embedding()`__ method for word2vec\n",
    "* Use the same embedding matrix in title and desc vectorizer\n",
    "\n",
    "\n",
    "#### D) Going recurrent\n",
    "\n",
    "We've already learned that recurrent networks can do cool stuff in sequence modelling. Turns out, they're not useless for classification as well. With some tricks of course..\n",
    "\n",
    "* Like convolutional layers, LSTM should be pooled into a fixed-size vector with some of the poolings.\n",
    "* Since you know all the text in advance, use bidirectional RNN\n",
    "  * Run one LSTM from left to right\n",
    "  * Run another in parallel from right to left \n",
    "  * Concatenate their output sequences along unit axis (dim=-1)\n",
    "\n",
    "* It might be good idea to mix convolutions and recurrent layers differently for title and description\n",
    "\n",
    "\n",
    "#### E) Optimizing seriously\n",
    "\n",
    "* You don't necessarily need 100 epochs. Use early stopping. If you've never done this before, take a look at [early stopping callback](https://keras.io/callbacks/#earlystopping).\n",
    "  * In short, train until you notice that validation\n",
    "  * Maintain the best-on-validation snapshot via `model.save(file_name)`\n",
    "  * Plotting learning curves is usually a good idea\n",
    "  \n",
    "Good luck! And may the force be with you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
